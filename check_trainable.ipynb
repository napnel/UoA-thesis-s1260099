{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1002\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  var JS_MIME_TYPE = 'application/javascript';\n  var HTML_MIME_TYPE = 'text/html';\n  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  var CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    var script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    var cell = handle.cell;\n\n    var id = cell.output_area._bokeh_element_id;\n    var server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd, {\n        iopub: {\n          output: function(msg) {\n            var id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    var output_area = handle.output_area;\n    var output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      var bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      var script_attrs = bk_div.children[0].attributes;\n      for (var i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      var toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1002\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\": \"dM3QQsP+wXdHg42wTqW85BjZQdLNNIXqlPw/BgKoExPmTG7ZLML4EGqLMfqHT6ON\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\": \"8x57I4YuIfu8XyZfFo0XVr2WAT8EK4rh/uDe3wF7YuW2FNUSNEpJbsPaB1nJ2fz2\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\": \"3QTqdz9LyAm2i0sG5XTePsHec3UHWwVsrOL68SYRoAXsafvfAyqtQ+h440+qIBhS\"};\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.3.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.3.3.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import glob\n",
    "import random\n",
    "import argparse\n",
    "from numpy import isin\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Any, Optional\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import Callback\n",
    "from ray.tune import ProgressReporter\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.logger import UnifiedLogger\n",
    "from ray.tune.schedulers.pb2 import PB2\n",
    "from src.envs import BaseTradingEnv\n",
    "from src.utils import DataLoader, Preprocessor, backtest\n",
    "from src.utils.misc import get_agent_class\n",
    "from src.trainable.cross_validation_v2 import ExperimentCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(algo='A2C', criteria='timesteps_total', logdir='./experiments', max_timesteps=10000, metric='evaluation/episode_reward_mean', mode='max', num_samples=1, perturb=0.25, seed=3407, ticker='^N225')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = {\n",
    "    \"ticker\": \"^N225\",\n",
    "    \"algo\": \"A2C\",\n",
    "    \"max_timesteps\": 10000,\n",
    "    \"metric\": \"evaluation/episode_reward_mean\",\n",
    "    \"mode\": \"max\",\n",
    "    \"num_samples\": 1,\n",
    "    \"criteria\": \"timesteps_total\",\n",
    "    \"perturb\": 0.25,\n",
    "    \"seed\": 3407,\n",
    "    \"logdir\": \"./experiments\",\n",
    "}\n",
    "args = argparse.Namespace(**args)\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-15 10:00:59,835\tINFO services.py:1252 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    }
   ],
   "source": [
    "# ray.shutdown()\n",
    "ray.init(log_to_driver=False, num_gpus=0, local_mode=True)\n",
    "\n",
    "config = {\n",
    "    \"env\": \"BaseTradingEnv\",\n",
    "    \"env_config\": {},\n",
    "    \"evaluation_interval\": 1,\n",
    "    \"evaluation_num_episodes\": 1,\n",
    "    \"evaluation_config\": {\n",
    "        \"env_config\": {},\n",
    "        \"explore\": False,\n",
    "    },\n",
    "    \"num_workers\": 2,\n",
    "    \"framework\": \"torch\",\n",
    "    \"log_level\": \"WARN\",\n",
    "    \"timesteps_per_iteration\": 2500,\n",
    "    \"num_gpus\": 0,\n",
    "    \"seed\": args.seed,\n",
    "    \"_algo\": args.algo,\n",
    "    \"_ticker\": args.ticker,\n",
    "    \"_n_splits\": 3,\n",
    "    # \"lambda\": tune.sample_from(lambda spec: random.uniform(0.9, 1.0)),\n",
    "    # \"lr\": tune.sample_from(lambda spec: random.uniform(1e-3, 1e-5)),\n",
    "}\n",
    "\n",
    "# pb2 = PB2(\n",
    "#     time_attr=\"timesteps_total\",\n",
    "#     metric=\"evaluation/episode_reward_mean\",\n",
    "#     mode=\"max\",\n",
    "#     perturbation_interval=2500,\n",
    "#     quantile_fraction=0.25,  # copy bottom % with top %\n",
    "#     # Specifies the hyperparam search space\n",
    "#     hyperparam_bounds={\n",
    "#         \"lambda\": [0.9, 1.0],\n",
    "#         \"lr\": [1e-3, 1e-5],\n",
    "#     },\n",
    "# )\n",
    "\n",
    "timelog = str(datetime.date(datetime.now())) + \"_\" + datetime.time(datetime.now()).strftime(\"%H-%M\")\n",
    "\n",
    "reporter = CLIReporter(\n",
    "    {\n",
    "        \"episode_reward_mean\": \"episode_reward\",\n",
    "        \"evaluation/episode_reward_mean\": \"eval/episode_reward\",\n",
    "        \"timesteps_total\": \"steps\",\n",
    "        \"episodes_total\": \"episodes\",\n",
    "    },\n",
    "    max_report_frequency=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-15 10:01:08,976\tWARNING worker.py:500 -- `ray.get_gpu_ids()` will always return the empty list when called from the driver. This is because Ray does not manage GPU allocations to the driver process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":task_name:bundle_reservation_check_func\n",
      ":actor_name:ExperimentCV\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-15 10:01:11,315\tWARNING logger.py:318 -- Could not instantiate JsonLogger: [Errno 2] No such file or directory: 'c:\\\\Users\\\\xiang-lab\\\\Documents\\\\DRL-Trading\\\\experiments\\\\A2C_2021-11-15_10-01\\\\ExperimentCV_BaseTradingEnv_84a04_00000_0_2021-11-15_10-01-09\\\\splits_0\\\\params.json'.\n",
      "2021-11-15 10:01:11,316\tWARNING logger.py:318 -- Could not instantiate CSVLogger: [Errno 2] No such file or directory: 'c:\\\\Users\\\\xiang-lab\\\\Documents\\\\DRL-Trading\\\\experiments\\\\A2C_2021-11-15_10-01\\\\ExperimentCV_BaseTradingEnv_84a04_00000_0_2021-11-15_10-01-09\\\\splits_0\\\\progress.csv'.\n",
      "2021-11-15 10:01:11,325\tINFO trainer.py:760 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "2021-11-15 10:01:11,576\tWARNING trainer_template.py:186 -- `execution_plan` functions should accept `trainer`, `workers`, and `config` as args!\n",
      "2021-11-15 10:01:11,577\tWARNING deprecation.py:39 -- DeprecationWarning: `simple_optimizer` has been deprecated. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":actor_name:RolloutWorker\n",
      ":actor_name:RolloutWorker\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-15 10:01:11,725\tINFO trainable.py:394 -- Restored on 172.22.130.108 from checkpoint: c:\\Users\\xiang-lab\\Documents\\DRL-Trading\\experiments\\A2C_2021-11-15_10-01\\ExperimentCV_BaseTradingEnv_84a04_00000_0_2021-11-15_10-01-09\\splits_0\\checkpoint_000000\\checkpoint-0\n",
      "2021-11-15 10:01:11,726\tINFO trainable.py:401 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': None, '_time_total': 0.0, '_episodes_total': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\xiang-lab\\\\Documents\\\\DRL-Trading\\\\experiments\\\\A2C_2021-11-15_10-01\\\\ExperimentCV_BaseTradingEnv_84a04_00000_0_2021-11-15_10-01-09\\\\']\n",
      "=============== 0 ===============\n",
      "['c:\\\\Users\\\\xiang-lab\\\\Documents\\\\DRL-Trading\\\\experiments\\\\A2C_2021-11-15_10-01\\\\ExperimentCV_BaseTradingEnv_84a04_00000_0_2021-11-15_10-01-09\\\\splits_0\\\\checkpoint_000000']\n",
      "c:\\Users\\xiang-lab\\Documents\\DRL-Trading\\experiments\\A2C_2021-11-15_10-01\\ExperimentCV_BaseTradingEnv_84a04_00000_0_2021-11-15_10-01-09\\splits_0\\checkpoint_000000\\checkpoint-0\n",
      "agent logdir:  c:\\Users\\xiang-lab\\Documents\\DRL-Trading\\experiments\\A2C_2021-11-15_10-01\\ExperimentCV_BaseTradingEnv_84a04_00000_0_2021-11-15_10-01-09\\splits_2\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-15 10:01:16,780\tINFO trainable.py:394 -- Restored on 172.22.130.108 from checkpoint: c:\\Users\\xiang-lab\\Documents\\DRL-Trading\\experiments\\A2C_2021-11-15_10-01\\ExperimentCV_BaseTradingEnv_84a04_00000_0_2021-11-15_10-01-09\\splits_1\\checkpoint_000000\\checkpoint-0\n",
      "2021-11-15 10:01:16,781\tINFO trainable.py:401 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': None, '_time_total': 0.0, '_episodes_total': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== 0 ===============\n",
      "['c:\\\\Users\\\\xiang-lab\\\\Documents\\\\DRL-Trading\\\\experiments\\\\A2C_2021-11-15_10-01\\\\ExperimentCV_BaseTradingEnv_84a04_00000_0_2021-11-15_10-01-09\\\\splits_1\\\\checkpoint_000000']\n",
      "c:\\Users\\xiang-lab\\Documents\\DRL-Trading\\experiments\\A2C_2021-11-15_10-01\\ExperimentCV_BaseTradingEnv_84a04_00000_0_2021-11-15_10-01-09\\splits_1\\checkpoint_000000\\checkpoint-0\n",
      "agent logdir:  c:\\Users\\xiang-lab\\Documents\\DRL-Trading\\experiments\\A2C_2021-11-15_10-01\\ExperimentCV_BaseTradingEnv_84a04_00000_0_2021-11-15_10-01-09\\splits_2\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-15 10:01:23,885\tINFO trainable.py:394 -- Restored on 172.22.130.108 from checkpoint: c:\\Users\\xiang-lab\\Documents\\DRL-Trading\\experiments\\A2C_2021-11-15_10-01\\ExperimentCV_BaseTradingEnv_84a04_00000_0_2021-11-15_10-01-09\\splits_2\\checkpoint_000000\\checkpoint-0\n",
      "2021-11-15 10:01:23,886\tINFO trainable.py:401 -- Current state after restoring: {'_iteration': 0, '_timesteps_total': None, '_time_total': 0.0, '_episodes_total': None}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== 0 ===============\n",
      "['c:\\\\Users\\\\xiang-lab\\\\Documents\\\\DRL-Trading\\\\experiments\\\\A2C_2021-11-15_10-01\\\\ExperimentCV_BaseTradingEnv_84a04_00000_0_2021-11-15_10-01-09\\\\splits_2\\\\checkpoint_000000']\n",
      "c:\\Users\\xiang-lab\\Documents\\DRL-Trading\\experiments\\A2C_2021-11-15_10-01\\ExperimentCV_BaseTradingEnv_84a04_00000_0_2021-11-15_10-01-09\\splits_2\\checkpoint_000000\\checkpoint-0\n",
      "agent logdir:  c:\\Users\\xiang-lab\\Documents\\DRL-Trading\\experiments\\A2C_2021-11-15_10-01\\ExperimentCV_BaseTradingEnv_84a04_00000_0_2021-11-15_10-01-09\\splits_2\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-15 10:01:34,295\tINFO trainable.py:394 -- Restored on 172.22.130.108 from checkpoint: c:\\Users\\xiang-lab\\Documents\\DRL-Trading\\experiments\\A2C_2021-11-15_10-01\\ExperimentCV_BaseTradingEnv_84a04_00000_0_2021-11-15_10-01-09\\splits_0\\checkpoint_000001\\checkpoint-1\n",
      "2021-11-15 10:01:34,295\tINFO trainable.py:401 -- Current state after restoring: {'_iteration': 1, '_timesteps_total': None, '_time_total': 4.988656997680664, '_episodes_total': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 10.5/31.9 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/13.66 GiB heap, 0.0/6.83 GiB objects\n",
      "Result logdir: c:\\Users\\xiang-lab\\Documents\\DRL-Trading\\experiments\\A2C_2021-11-15_10-01\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+-------+\n",
      "| Trial name                              | status   | loc   |\n",
      "|-----------------------------------------+----------+-------|\n",
      "| ExperimentCV_BaseTradingEnv_84a04_00000 | RUNNING  |       |\n",
      "+-----------------------------------------+----------+-------+\n",
      "\n",
      "\n",
      "Result for ExperimentCV_BaseTradingEnv_84a04_00000:\n",
      "  agent_timesteps_total: 5200.0\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_10-01-34\n",
      "  done: false\n",
      "  episode_len_mean: 1218.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: -0.16228584394204995\n",
      "  episode_reward_mean: -0.37043221600976156\n",
      "  episode_reward_min: -0.4715229780280037\n",
      "  episodes_this_iter: 4.0\n",
      "  episodes_total: 4.0\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 237.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 0.025709707187752784\n",
      "    episode_reward_mean: 0.0021351363622864974\n",
      "    episode_reward_min: -0.02143943446317979\n",
      "    episodes_this_iter: 2.6666666666666665\n",
      "    hist_stats: {}\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.03069988806361236\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.3849692950445047\n",
      "      mean_inference_ms: 3.2540509464035487\n",
      "      mean_raw_obs_processing_ms: 0.1159647405123617\n",
      "  experiment_id: 18d86cfe6a694514b288edebe907b314\n",
      "  hostname: DESKTOP-84GJ5JV\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          policy_entropy: 219.67168172200522\n",
      "          policy_loss: -0.07482033967971802\n",
      "          vf_loss: 0.0186174800619483\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 5200.0\n",
      "    num_agent_steps_trained: 5200.0\n",
      "    num_steps_sampled: 5200.0\n",
      "    num_steps_trained: 5200.0\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 172.22.130.108\n",
      "  num_healthy_workers: 2.0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 39.31919413919414\n",
      "    gpu_util_percent0: 0.1314908424908425\n",
      "    ram_util_percent: 32.09285714285714\n",
      "    vram_util_percent0: 0.11024860556110556\n",
      "  pid: 14740\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.045230139535549906\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.3823242592299483\n",
      "    mean_inference_ms: 2.8318390350357205\n",
      "    mean_raw_obs_processing_ms: 0.21056540656391817\n",
      "  time_since_restore: 7.44909652074178\n",
      "  time_this_iter_s: 7.44909652074178\n",
      "  time_total_s: 7.44909652074178\n",
      "  timers:\n",
      "    learn_throughput: 8717.074666666667\n",
      "    learn_time_ms: 23.838333333333335\n",
      "    load_throughput: 834503.1916666665\n",
      "    load_time_ms: 0.26666666666666666\n",
      "    sample_throughput: 700.9143333333333\n",
      "    sample_time_ms: 296.90299999999996\n",
      "    update_time_ms: 3.991\n",
      "  timestamp: 1636938094\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 5200.0\n",
      "  training_iteration: 1.0\n",
      "  trial_id: 84a04_00000\n",
      "  \n",
      "=============== 1 ===============\n",
      "['c:\\\\Users\\\\xiang-lab\\\\Documents\\\\DRL-Trading\\\\experiments\\\\A2C_2021-11-15_10-01\\\\ExperimentCV_BaseTradingEnv_84a04_00000_0_2021-11-15_10-01-09\\\\splits_0\\\\checkpoint_000000', 'c:\\\\Users\\\\xiang-lab\\\\Documents\\\\DRL-Trading\\\\experiments\\\\A2C_2021-11-15_10-01\\\\ExperimentCV_BaseTradingEnv_84a04_00000_0_2021-11-15_10-01-09\\\\splits_0\\\\checkpoint_000001']\n",
      "c:\\Users\\xiang-lab\\Documents\\DRL-Trading\\experiments\\A2C_2021-11-15_10-01\\ExperimentCV_BaseTradingEnv_84a04_00000_0_2021-11-15_10-01-09\\splits_0\\checkpoint_000001\\checkpoint-1\n",
      "agent logdir:  c:\\Users\\xiang-lab\\Documents\\DRL-Trading\\experiments\\A2C_2021-11-15_10-01\\ExperimentCV_BaseTradingEnv_84a04_00000_0_2021-11-15_10-01-09\\splits_2\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-15 10:01:44,709\tINFO trainable.py:394 -- Restored on 172.22.130.108 from checkpoint: c:\\Users\\xiang-lab\\Documents\\DRL-Trading\\experiments\\A2C_2021-11-15_10-01\\ExperimentCV_BaseTradingEnv_84a04_00000_0_2021-11-15_10-01-09\\splits_1\\checkpoint_000001\\checkpoint-1\n",
      "2021-11-15 10:01:44,709\tINFO trainable.py:401 -- Current state after restoring: {'_iteration': 1, '_timesteps_total': None, '_time_total': 7.054163217544556, '_episodes_total': 4}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== 1 ===============\n",
      "['c:\\\\Users\\\\xiang-lab\\\\Documents\\\\DRL-Trading\\\\experiments\\\\A2C_2021-11-15_10-01\\\\ExperimentCV_BaseTradingEnv_84a04_00000_0_2021-11-15_10-01-09\\\\splits_1\\\\checkpoint_000000', 'c:\\\\Users\\\\xiang-lab\\\\Documents\\\\DRL-Trading\\\\experiments\\\\A2C_2021-11-15_10-01\\\\ExperimentCV_BaseTradingEnv_84a04_00000_0_2021-11-15_10-01-09\\\\splits_1\\\\checkpoint_000001']\n",
      "c:\\Users\\xiang-lab\\Documents\\DRL-Trading\\experiments\\A2C_2021-11-15_10-01\\ExperimentCV_BaseTradingEnv_84a04_00000_0_2021-11-15_10-01-09\\splits_1\\checkpoint_000001\\checkpoint-1\n",
      "agent logdir:  c:\\Users\\xiang-lab\\Documents\\DRL-Trading\\experiments\\A2C_2021-11-15_10-01\\ExperimentCV_BaseTradingEnv_84a04_00000_0_2021-11-15_10-01-09\\splits_2\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-15 10:01:54,856\tINFO trainable.py:394 -- Restored on 172.22.130.108 from checkpoint: c:\\Users\\xiang-lab\\Documents\\DRL-Trading\\experiments\\A2C_2021-11-15_10-01\\ExperimentCV_BaseTradingEnv_84a04_00000_0_2021-11-15_10-01-09\\splits_2\\checkpoint_000001\\checkpoint-1\n",
      "2021-11-15 10:01:54,857\tINFO trainable.py:401 -- Current state after restoring: {'_iteration': 1, '_timesteps_total': None, '_time_total': 10.304469347000122, '_episodes_total': 6}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== 1 ===============\n",
      "['c:\\\\Users\\\\xiang-lab\\\\Documents\\\\DRL-Trading\\\\experiments\\\\A2C_2021-11-15_10-01\\\\ExperimentCV_BaseTradingEnv_84a04_00000_0_2021-11-15_10-01-09\\\\splits_2\\\\checkpoint_000000', 'c:\\\\Users\\\\xiang-lab\\\\Documents\\\\DRL-Trading\\\\experiments\\\\A2C_2021-11-15_10-01\\\\ExperimentCV_BaseTradingEnv_84a04_00000_0_2021-11-15_10-01-09\\\\splits_2\\\\checkpoint_000001']\n",
      "c:\\Users\\xiang-lab\\Documents\\DRL-Trading\\experiments\\A2C_2021-11-15_10-01\\ExperimentCV_BaseTradingEnv_84a04_00000_0_2021-11-15_10-01-09\\splits_2\\checkpoint_000001\\checkpoint-1\n",
      "agent logdir:  c:\\Users\\xiang-lab\\Documents\\DRL-Trading\\experiments\\A2C_2021-11-15_10-01\\ExperimentCV_BaseTradingEnv_84a04_00000_0_2021-11-15_10-01-09\\splits_2\\\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-15 10:02:04,597\tINFO tune.py:617 -- Total run time: 55.77 seconds (55.61 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Memory usage on this node: 10.3/31.9 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 8.0/8 CPUs, 0/0 GPUs, 0.0/13.66 GiB heap, 0.0/6.83 GiB objects\n",
      "Result logdir: c:\\Users\\xiang-lab\\Documents\\DRL-Trading\\experiments\\A2C_2021-11-15_10-01\n",
      "Number of trials: 1/1 (1 RUNNING)\n",
      "+-----------------------------------------+----------+----------------------+------------------+-----------------------+---------+------------+\n",
      "| Trial name                              | status   | loc                  |   episode_reward |   eval/episode_reward |   steps |   episodes |\n",
      "|-----------------------------------------+----------+----------------------+------------------+-----------------------+---------+------------|\n",
      "| ExperimentCV_BaseTradingEnv_84a04_00000 | RUNNING  | 172.22.130.108:14740 |        -0.370432 |            0.00213514 |    5200 |          4 |\n",
      "+-----------------------------------------+----------+----------------------+------------------+-----------------------+---------+------------+\n",
      "\n",
      "\n",
      "Result for ExperimentCV_BaseTradingEnv_84a04_00000:\n",
      "  agent_timesteps_total: 13000.0\n",
      "  custom_metrics: {}\n",
      "  date: 2021-11-15_10-02-04\n",
      "  done: true\n",
      "  episode_len_mean: 1218.0\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 0.13781059080901711\n",
      "  episode_reward_mean: -0.26811345654865976\n",
      "  episode_reward_min: -0.5545931989587297\n",
      "  episodes_this_iter: 6.666666666666667\n",
      "  episodes_total: 10.666666666666666\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 237.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 0.10633239998682775\n",
      "    episode_reward_mean: 0.10633239998682775\n",
      "    episode_reward_min: 0.10633239998682775\n",
      "    episodes_this_iter: 1.0\n",
      "    hist_stats: {}\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.031103713057298116\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.3790017033069291\n",
      "      mean_inference_ms: 3.301562251866303\n",
      "      mean_raw_obs_processing_ms: 0.1098902863669804\n",
      "  experiment_id: 18d86cfe6a694514b288edebe907b314\n",
      "  hostname: DESKTOP-84GJ5JV\n",
      "  info:\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          allreduce_latency: 0.0\n",
      "          policy_entropy: 219.65546671549478\n",
      "          policy_loss: -0.2679765895009041\n",
      "          vf_loss: 0.01413891122986873\n",
      "        model: {}\n",
      "    num_agent_steps_sampled: 13000.0\n",
      "    num_agent_steps_trained: 13000.0\n",
      "    num_steps_sampled: 13000.0\n",
      "    num_steps_trained: 13000.0\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 172.22.130.108\n",
      "  num_healthy_workers: 2.0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 32.32435897435897\n",
      "    gpu_util_percent0: 0.13565934065934063\n",
      "    ram_util_percent: 32.37985347985347\n",
      "    vram_util_percent0: 0.10905338151431902\n",
      "  pid: 14740\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.03981001410325622\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.3544249614173758\n",
      "    mean_inference_ms: 2.3648413606857206\n",
      "    mean_raw_obs_processing_ms: 0.18284090533535421\n",
      "  time_since_restore: 17.44311984380086\n",
      "  time_this_iter_s: 9.994023323059082\n",
      "  time_total_s: 17.44311984380086\n",
      "  timers:\n",
      "    learn_throughput: 10471.279333333334\n",
      "    learn_time_ms: 19.115333333333336\n",
      "    load_throughput: 1172635.3493333333\n",
      "    load_time_ms: 0.23333333333333336\n",
      "    sample_throughput: 841.6370000000001\n",
      "    sample_time_ms: 238.00266666666667\n",
      "    update_time_ms: 3.263333333333333\n",
      "  timestamp: 1636938124\n",
      "  timesteps_since_restore: 0\n",
      "  timesteps_total: 13000.0\n",
      "  training_iteration: 2.0\n",
      "  trial_id: 84a04_00000\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 10.3/31.9 GiB\n",
      "Using FIFO scheduling algorithm.\n",
      "Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/13.66 GiB heap, 0.0/6.83 GiB objects\n",
      "Result logdir: c:\\Users\\xiang-lab\\Documents\\DRL-Trading\\experiments\\A2C_2021-11-15_10-01\n",
      "Number of trials: 1/1 (1 TERMINATED)\n",
      "+-----------------------------------------+------------+-------+------------------+-----------------------+---------+------------+\n",
      "| Trial name                              | status     | loc   |   episode_reward |   eval/episode_reward |   steps |   episodes |\n",
      "|-----------------------------------------+------------+-------+------------------+-----------------------+---------+------------|\n",
      "| ExperimentCV_BaseTradingEnv_84a04_00000 | TERMINATED |       |        -0.268113 |              0.106332 |   13000 |    10.6667 |\n",
      "+-----------------------------------------+------------+-------+------------------+-----------------------+---------+------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analysis = tune.run(\n",
    "    ExperimentCV,\n",
    "    name=f\"{args.algo}_{timelog}\",\n",
    "    num_samples=args.num_samples,\n",
    "    metric=args.metric,\n",
    "    mode=args.mode,\n",
    "    stop={\"timesteps_total\": args.max_timesteps},\n",
    "    config=config,\n",
    "    progress_reporter=reporter,\n",
    "    local_dir=args.logdir,\n",
    "    resources_per_trial=tune.PlacementGroupFactory([{\"CPU\": 4}, {\"CPU\": 4}]),\n",
    "    # scheduler=pb2,\n",
    "    # reuse_actors=True,\n",
    "    # verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_reward_max</th>\n",
       "      <th>episode_reward_min</th>\n",
       "      <th>episode_reward_mean</th>\n",
       "      <th>episode_len_mean</th>\n",
       "      <th>episodes_this_iter</th>\n",
       "      <th>num_healthy_workers</th>\n",
       "      <th>timesteps_total</th>\n",
       "      <th>agent_timesteps_total</th>\n",
       "      <th>done</th>\n",
       "      <th>episodes_total</th>\n",
       "      <th>...</th>\n",
       "      <th>evaluation.sampler_perf.mean_raw_obs_processing_ms</th>\n",
       "      <th>evaluation.sampler_perf.mean_inference_ms</th>\n",
       "      <th>evaluation.sampler_perf.mean_action_processing_ms</th>\n",
       "      <th>evaluation.sampler_perf.mean_env_wait_ms</th>\n",
       "      <th>evaluation.sampler_perf.mean_env_render_ms</th>\n",
       "      <th>config.evaluation_config.explore</th>\n",
       "      <th>info.learner.default_policy.learner_stats.allreduce_latency</th>\n",
       "      <th>info.learner.default_policy.learner_stats.policy_entropy</th>\n",
       "      <th>info.learner.default_policy.learner_stats.policy_loss</th>\n",
       "      <th>info.learner.default_policy.learner_stats.vf_loss</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84a04_00000</th>\n",
       "      <td>0.137811</td>\n",
       "      <td>-0.554593</td>\n",
       "      <td>-0.268113</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13000.0</td>\n",
       "      <td>13000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10989</td>\n",
       "      <td>3.301562</td>\n",
       "      <td>0.031104</td>\n",
       "      <td>0.379002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>219.655467</td>\n",
       "      <td>-0.267977</td>\n",
       "      <td>0.014139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             episode_reward_max  episode_reward_min  episode_reward_mean  \\\n",
       "trial_id                                                                   \n",
       "84a04_00000            0.137811           -0.554593            -0.268113   \n",
       "\n",
       "             episode_len_mean  episodes_this_iter  num_healthy_workers  \\\n",
       "trial_id                                                                 \n",
       "84a04_00000            1218.0            6.666667                  2.0   \n",
       "\n",
       "             timesteps_total  agent_timesteps_total  done  episodes_total  \\\n",
       "trial_id                                                                    \n",
       "84a04_00000          13000.0                13000.0  True       10.666667   \n",
       "\n",
       "             ...  evaluation.sampler_perf.mean_raw_obs_processing_ms  \\\n",
       "trial_id     ...                                                       \n",
       "84a04_00000  ...                                            0.10989    \n",
       "\n",
       "             evaluation.sampler_perf.mean_inference_ms  \\\n",
       "trial_id                                                 \n",
       "84a04_00000                                   3.301562   \n",
       "\n",
       "             evaluation.sampler_perf.mean_action_processing_ms  \\\n",
       "trial_id                                                         \n",
       "84a04_00000                                           0.031104   \n",
       "\n",
       "             evaluation.sampler_perf.mean_env_wait_ms  \\\n",
       "trial_id                                                \n",
       "84a04_00000                                  0.379002   \n",
       "\n",
       "             evaluation.sampler_perf.mean_env_render_ms  \\\n",
       "trial_id                                                  \n",
       "84a04_00000                                         0.0   \n",
       "\n",
       "             config.evaluation_config.explore  \\\n",
       "trial_id                                        \n",
       "84a04_00000                             False   \n",
       "\n",
       "             info.learner.default_policy.learner_stats.allreduce_latency  \\\n",
       "trial_id                                                                   \n",
       "84a04_00000                                                0.0             \n",
       "\n",
       "             info.learner.default_policy.learner_stats.policy_entropy  \\\n",
       "trial_id                                                                \n",
       "84a04_00000                                         219.655467          \n",
       "\n",
       "            info.learner.default_policy.learner_stats.policy_loss  \\\n",
       "trial_id                                                            \n",
       "84a04_00000                                          -0.267977      \n",
       "\n",
       "            info.learner.default_policy.learner_stats.vf_loss  \n",
       "trial_id                                                       \n",
       "84a04_00000                                          0.014139  \n",
       "\n",
       "[1 rows x 70 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ExperimentCV_BaseTradingEnv_84a04_00000]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials = analysis.trials\n",
    "trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\XIANG-~1\\AppData\\Local\\Temp/ipykernel_14740/3047324116.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0manalysis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Trainer' is not defined"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(config=analysis.best_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-11 15:24:30,210\tINFO trainable.py:394 -- Restored on 172.22.130.108 from checkpoint: c:\\Users\\xiang-lab\\Documents\\DRL-Trading\\experiments\\PPO_2021-11-11_15-08\\Trainer_BaseTradingEnv_cba21_00000_0_2021-11-11_15-08-31\\splits_0\\checkpoint_000025\\checkpoint-25\n",
      "2021-11-11 15:24:30,210\tINFO trainable.py:401 -- Current state after restoring: {'_iteration': 25, '_timesteps_total': None, '_time_total': 191.8985846042633, '_episodes_total': 82}\n",
      "2021-11-11 15:24:30,222\tINFO trainable.py:394 -- Restored on 172.22.130.108 from checkpoint: c:\\Users\\xiang-lab\\Documents\\DRL-Trading\\experiments\\PPO_2021-11-11_15-08\\Trainer_BaseTradingEnv_cba21_00000_0_2021-11-11_15-08-31\\splits_1\\checkpoint_000025\\checkpoint-25\n",
      "2021-11-11 15:24:30,223\tINFO trainable.py:401 -- Current state after restoring: {'_iteration': 25, '_timesteps_total': None, '_time_total': 185.76498436927795, '_episodes_total': 82}\n",
      "2021-11-11 15:24:30,235\tINFO trainable.py:394 -- Restored on 172.22.130.108 from checkpoint: c:\\Users\\xiang-lab\\Documents\\DRL-Trading\\experiments\\PPO_2021-11-11_15-08\\Trainer_BaseTradingEnv_cba21_00000_0_2021-11-11_15-08-31\\splits_2\\checkpoint_000025\\checkpoint-25\n",
      "2021-11-11 15:24:30,235\tINFO trainable.py:401 -- Current state after restoring: {'_iteration': 25, '_timesteps_total': None, '_time_total': 186.47372817993164, '_episodes_total': 82}\n",
      "2021-11-11 15:24:30,247\tINFO trainable.py:394 -- Restored on 172.22.130.108 from checkpoint: c:\\Users\\xiang-lab\\Documents\\DRL-Trading\\experiments\\PPO_2021-11-11_15-08\\Trainer_BaseTradingEnv_cba21_00000_0_2021-11-11_15-08-31\\splits_3\\checkpoint_000025\\checkpoint-25\n",
      "2021-11-11 15:24:30,247\tINFO trainable.py:401 -- Current state after restoring: {'_iteration': 25, '_timesteps_total': None, '_time_total': 187.26723456382751, '_episodes_total': 82}\n",
      "2021-11-11 15:24:30,258\tINFO trainable.py:394 -- Restored on 172.22.130.108 from checkpoint: c:\\Users\\xiang-lab\\Documents\\DRL-Trading\\experiments\\PPO_2021-11-11_15-08\\Trainer_BaseTradingEnv_cba21_00000_0_2021-11-11_15-08-31\\splits_4\\checkpoint_000025\\checkpoint-25\n",
      "2021-11-11 15:24:30,258\tINFO trainable.py:401 -- Current state after restoring: {'_iteration': 25, '_timesteps_total': None, '_time_total': 186.66784238815308, '_episodes_total': 82}\n",
      "2021-11-11 15:24:30,259\tINFO trainable.py:394 -- Restored on 172.22.130.108 from checkpoint: c:\\Users\\xiang-lab\\Documents\\DRL-Trading\\experiments\\PPO_2021-11-11_15-08\\Trainer_BaseTradingEnv_cba21_00000_0_2021-11-11_15-08-31\\checkpoint_000025\\\n",
      "2021-11-11 15:24:30,259\tINFO trainable.py:401 -- Current state after restoring: {'_iteration': 25, '_timesteps_total': None, '_time_total': 187.61447482109068, '_episodes_total': 82.0}\n"
     ]
    }
   ],
   "source": [
    "trainer.restore(analysis.best_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('c:/Users/xiang-lab/Documents/DRL-Trading/experiments/PPO_2021-11-11_15-08/Trainer_BaseTradingEnv_cba21_00000_0_2021-11-11_15-08-31')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = pathlib.Path(analysis.best_checkpoint)\n",
    "checkpoint.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-11 18:22:45,128\tWARNING worker.py:1227 -- The node with node id: fcbf58100f8b8345ac64b06812bc360267922fa0731b8b5fbb31424c and ip: 172.22.130.108 has been marked dead because the detector has missed too many heartbeats from it. This can happen when a raylet crashes unexpectedly or has lagging heartbeats.\n"
     ]
    }
   ],
   "source": [
    "for i, agent in enumerate(trainer.agents):\n",
    "    env_train = agent.workers.local_worker().env\n",
    "    env_eval = agent.evaluation_workers.local_worker().env\n",
    "    backtest(env_train, agent, save_dir=os.path.join(checkpoint.parent, f\"splits_{i}\", \"last-stats-train\"), plot=False)\n",
    "    backtest(env_eval, agent, save_dir=os.path.join(checkpoint.parent, f\"splits_{i}\", \"last-stats-eval\"), plot=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "92494b380cdd7d1d1ced08fe7bc7df853d898bcea1d66a2a33078fd6ace70ca7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('drl-trading': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
